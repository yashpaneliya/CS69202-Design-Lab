{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwyCyOakwmJR",
        "outputId": "d9b0d701-d209-4005-8f41-b488650a9af4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "EqpvjAQHxEyM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLGA42xGLbtQ",
        "outputId": "464feba2-b5c7-4b47-ae19-e8a0c1f80994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = ['हूँ', 'हो','हूं', 'मैं','में','तू', 'है', 'हैं','अथव', 'अद', 'अध', 'अन', 'अपन', 'अभ', 'अल', 'आग', 'आद', 'आपक', 'इत', 'इतय', 'इनक', 'इनस', 'इसक', 'इसम', 'इसल', 'उनक', 'उनस', 'उसक', 'एव', 'ऐस', 'कभ', 'करत', 'करन', 'कह', 'कहत', 'गय', 'जबक', 'जर', 'जह', 'झक', 'तथ', 'तन', 'तर', 'दब', 'दर', 'दव', 'धर', 'नक', 'नस', 'नह', 'पड', 'पहल', 'बड', 'बन', 'बह', 'यत', 'यद', 'यम', 'रख', 'रत', 'रव', 'रह', 'रहत', 'लक', 'वग', 'वय', 'वर', 'वग़', 'सक', 'सकत', 'सबस', 'सभ', 'सम', 'सर', 'सस', 'हमन', 'हर', 'था', 'दें', 'थी','ले', 'लो', 'थे', 'होगा', 'होगी', 'होंगे', 'ख़ास', 'बहुत', 'बार', 'वाले', 'वाली', 'वाला', 'जब', 'जहाँ', 'जा', 'जिस', 'जिन्हें', 'जिन्हों', 'जिसे', 'जिसका', 'जिसकी','जिसके', 'जिसमें', 'जिधर', 'के', 'का', 'की', 'को', 'कि', 'इस', 'उस', 'उसे', 'उन', 'उन्हें', 'उन्हों', 'उनका', 'उनकी', 'उनके','उनसे', 'अपना', 'अपनी', 'अपने', 'आदि', 'इत्यादि', 'इन्हें', 'इन्हों', 'इनका', 'इनकी', 'इनके', 'इनसे', 'जैसा', 'जैसे','अंदर', 'अत', 'अदि', 'अप', 'अपना', 'अपनि', 'अपनी', 'अपने', 'अभि', 'अभी', 'आदि', 'आप', 'इंहिं', 'इंहें', 'इंहों', 'इतयादि', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकि', 'इसकी', 'इसके', 'इसमें', 'इसि', 'इसी', 'इसे', 'उंहिं', 'उंहें', 'उंहों', 'उन', 'उनका', 'उनकि', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसि', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'एसे', 'ऐसे', 'ओर', 'और', 'कइ', 'कई', 'कर', 'करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफि', 'काफ़ी', 'कि', 'किंहें', 'किंहों', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसि', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोइ', 'कोई', 'कोन', 'कोनसा', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जहां', 'जा', 'जिंहें', 'जिंहों', 'जितना', 'जिधर', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जेसा', 'जेसे', 'जैसा', 'जैसे' , 'तैसा', 'तैसे', 'इसलिए', 'इसके अलावा', 'फिर', 'अगर', 'कि', 'की', 'के बारे में', 'किसी तरह', 'कोई', 'कुछ', 'कुल','जितना', 'तक', 'तो', 'थी', 'थे', 'था', 'ने', 'पर', 'जा', 'जो', 'सबसे', 'संग','से', 'तक', 'साथ', 'ही', 'हुआ', 'हुई', 'हुए', 'होता', 'होती', 'ह']\n",
        "# remove duplicate stop words\n",
        "stop_set = set()\n",
        "for word in stop_words:\n",
        "  stop_set.add(word)\n",
        "print(\"No. of stop words: \", len(stop_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXAfTNYE4S3b",
        "outputId": "71ce4d91-3153-4328-c31f-d3e0501e4c6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of stop words:  235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/final_stopwords.txt', 'r', encoding='utf8') as file:\n",
        "    for line in file:\n",
        "        word = line.strip()  # remove newline character from the end of the line\n",
        "        stop_set.add(word)  # add the word to the set\n",
        "print(\"No. of stop words: \", len(stop_set))"
      ],
      "metadata": {
        "id": "EbhhkJbdLNx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a3662b-62ce-4d87-e105-d7807b68a675"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of stop words:  422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords_hindi(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    # print(tokens)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_set]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text\n",
        "\n",
        "def remove_stopwords_english(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    # print(tokens)\n",
        "    filtered_tokens = [word for word in tokens if word not in set(stopwords.words('english'))]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text"
      ],
      "metadata": {
        "id": "rofZQ7rVKJLk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing punctuations\n",
        "def remove_punctuations(text):\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "CEr7dOV8OUeD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # tokenize and check unique words\n",
        "def tokenize_unique_save(col):\n",
        "  unique = set()\n",
        "  for cell in col:\n",
        "    tokens = word_tokenize(cell)\n",
        "    for token in tokens:\n",
        "      unique.add(token)\n",
        "  return unique\n",
        "\n",
        "# unique_list = list()\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/unique.txt', 'w') as file:\n",
        "#   for word in tokenize_unique_save(df['text']):\n",
        "#     file.write(str(word)+'\\n')\n",
        "#   file.close()\n",
        "\n",
        "# print(tokenize_unique_save(df['text']))"
      ],
      "metadata": {
        "id": "bmI_DX9C0Jkr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic_transliteration emot"
      ],
      "metadata": {
        "id": "BP0ejfUhvuyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e13fc7a-7d14-48d5-8f8e-da24048d10f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic_transliteration\n",
            "  Downloading indic_transliteration-2.3.44-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emot\n",
            "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (2022.10.31)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (0.7.0)\n",
            "Collecting roman\n",
            "  Downloading roman-4.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from indic_transliteration) (0.10.2)\n",
            "Collecting backports.functools-lru-cache\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer->indic_transliteration) (8.1.3)\n",
            "Installing collected packages: emot, roman, backports.functools-lru-cache, indic_transliteration\n",
            "Successfully installed backports.functools-lru-cache-1.6.4 emot-3.1 indic_transliteration-2.3.44 roman-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# Define preprocessing functions\n",
        "def preprocess_hindi_text(text):\n",
        "    # Remove unnecessary symbols\n",
        "    text = re.sub(r'[^\\u0900-\\u097F\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove leading/trailing spaces\n",
        "    text = text.strip()\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def transliterate_hindi(text):\n",
        "    # Transliterate Hindi text to English\n",
        "    english_text = transliterate(text, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
        "    return english_text.lower()\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "def extract_emojis(text):\n",
        "    # Extract emojis from text\n",
        "    emojis = ''.join(c for c in text if c in ''.join(chr(i) for i in range(0x1F300, 0x1F6FF+1)))\n",
        "    return emojis\n",
        "\n",
        "def extract_raw_english(text):\n",
        "    # Remove unnecessary symbols\n",
        "    text = re.sub(r'[^a-z^A-Z]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove leading/trailing spaces\n",
        "    text = text.strip()\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "Mq5PTr2O90J2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emot.emo_unicode import UNICODE_EMOJI\n",
        " # Function for converting emojis into word\n",
        "def convert_emojis(text):\n",
        "    for e in UNICODE_EMOJI:\n",
        "        text = text.replace(e, (UNICODE_EMOJI[e]+' ').replace(':',''))\n",
        "    return text\n",
        "\n",
        "convert_emojis('😍😎👸👈🎠👫👸👈👗💃👀👩😋😍👈👸👰 पगली बहोत शोकीन तुजे डोली बिठाके लेके तेरे कपड़...')"
      ],
      "metadata": {
        "id": "ZRU8HSS4GFLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6f90750f-1d82-4173-a8a0-0fa456b40c4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'smiling_face_with_heart-eyes smiling_face_with_sunglasses princess backhand_index_pointing_left carousel_horse woman_and_man_holding_hands princess backhand_index_pointing_left dress woman_dancing eyes woman face_savoring_food smiling_face_with_heart-eyes backhand_index_pointing_left princess person_with_veil  पगली बहोत शोकीन तुजे डोली बिठाके लेके तेरे कपड़...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/abusive_text.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h2eUSc_EtFuK",
        "outputId": "30f1f64b-d455-4d5b-fb8e-965a7fbe2983"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                       text\n",
              "0      0              भीड़ में  बहुत  हब्सी मिलेंगे\n",
              "1      0  साले बेवकूफ अपनी मां मक्खियां  तो हटा दें\n",
              "2      0           बुर देदो तो मुह में लंड ले लो तो\n",
              "3      0       कुत्ता वहा है चिल्ला तू क्यों रहा है\n",
              "4      1  चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b146e970-1a36-45f1-bc90-6a0591fdb6d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>भीड़ में  बहुत  हब्सी मिलेंगे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>साले बेवकूफ अपनी मां मक्खियां  तो हटा दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>बुर देदो तो मुह में लंड ले लो तो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>कुत्ता वहा है चिल्ला तू क्यों रहा है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b146e970-1a36-45f1-bc90-6a0591fdb6d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b146e970-1a36-45f1-bc90-6a0591fdb6d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b146e970-1a36-45f1-bc90-6a0591fdb6d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################################# START PRE_PROCESSING ###################################################################################\n",
        "\n",
        "# remove punctuation from text\n",
        "df['Clean Text'] = df['text'].apply(remove_punctuations)\n",
        "\n",
        "# convert emoji to text\n",
        "df['Clean Text'] = df['Clean Text'].apply(convert_emojis)\n",
        "\n",
        "# remove digits from text\n",
        "df['Clean Text'] = df['Clean Text'].str.replace('\\d+',' ')\n",
        "\n",
        "# remove stop words from hindi\n",
        "df['Clean Text'] = df['Clean Text'].apply(remove_stopwords_hindi)\n",
        "\n",
        "df['final_text'] = df['Clean Text']"
      ],
      "metadata": {
        "id": "HYj51ON6fIdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341185c6-95ad-409a-e332-3c4150b31d8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-800337df5c8d>:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Clean Text'] = df['Clean Text'].str.replace('\\d+',' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf, valdf = train_test_split(df, train_size=0.8)"
      ],
      "metadata": {
        "id": "Rpx4KHGVgO7T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "id": "JdYRR0qFvqo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f4e40d-534e-4854-a9da-0de0f72c111e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.0.0+cu118)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.autograd import Variable \n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "A-0F-x1gFibo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "NoH1eQWnHYKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7fe412e-0e95-4fe4-8ff9-4205d712b0bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "  for text in data:\n",
        "        yield word_tokenize(text)"
      ],
      "metadata": {
        "id": "Kb2EGBliXofm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max sequence length\n",
        "max_seq_length = 100\n",
        "# build vocab\n",
        "vocab = build_vocab_from_iterator(build_vocab(df['final_text']), specials=[\"UNK\"])\n",
        "# The vocabulary block converts a list of tokens into integers.\n",
        "vocab.set_default_index(vocab[\"UNK\"])"
      ],
      "metadata": {
        "id": "aTOFnxxUT-7z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding each sentence as a sequence of integer\n",
        "encoded_train_data = []\n",
        "def encode_word2int(data):\n",
        "  word2int = []\n",
        "  for text in data:\n",
        "    tokens = word_tokenize(text)\n",
        "    word2int.append([vocab[word] for word in tokens])\n",
        "  return word2int"
      ],
      "metadata": {
        "id": "GrifYwuNktmj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/hindi_test.csv')"
      ],
      "metadata": {
        "id": "ll3ca_C-jzGC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "# remove punctuation from text\n",
        "test_df['Clean Text'] = test_df['text'].apply(remove_punctuations)\n",
        "\n",
        "# convert emoji to text\n",
        "test_df['Clean Text'] = test_df['Clean Text'].apply(convert_emojis)\n",
        "\n",
        "# remove digits from text\n",
        "test_df['Clean Text'] = test_df['Clean Text'].str.replace('\\d+',' ')\n",
        "\n",
        "# remove stop words from hindi\n",
        "test_df['Clean Text'] = test_df['Clean Text'].apply(remove_stopwords_hindi)\n",
        "\n",
        "test_df['final_text'] = test_df['Clean Text']\n",
        "\n",
        "test_df.head(10)"
      ],
      "metadata": {
        "id": "TzvNnhBK5FRU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "8d19c5b3-0cba-4cbc-ff8b-6f98f0dea59c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-8fdc1b2fe94a>:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test_df['Clean Text'] = test_df['Clean Text'].str.replace('\\d+',' ')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text  \\\n",
              "0      0  मैं ये नही सोच रहा की इसे निकले कैसे मैं ये सो...   \n",
              "1      1        और दिवाली में भी पूरा देश पड़ाका नहीं फोडात   \n",
              "2      1      कुत्ता बिल्ली पाल लेना मगर गलत फहमी कभी नहीं।   \n",
              "3      0      तेरी गांड में प्याज काट देगा गुज्जर भोसड़ी के   \n",
              "4      1            बंगाली साड़ी ऐसे नहीं पहना जाता है दीदी   \n",
              "5      1  ऐ इंडिया है यह आदमी दो बार जीता है  एक बार मरत...   \n",
              "6      1  अक्कड़ बक्कड़ बंबे बो  डीजल नब्बे पेट्रोल सौ  ...   \n",
              "7      1  एक तीर एक कमान आदिवासी एक समान एक तीर एक कमान ...   \n",
              "8      1  आपका बहुत बड़ा फैन हूं असद ओवैसी साहब मैं आपका...   \n",
              "9      0                          तुम सब चूतिया हो रोटी राम   \n",
              "\n",
              "                                          Clean Text  \\\n",
              "0  नही सोच निकले सोच फंसा कैसेface_with_tears_of_...   \n",
              "1                            दिवाली देश पड़ाका फोडात   \n",
              "2              कुत्ता बिल्ली पाल लेना गलत फहमी नहीं।   \n",
              "3             तेरी गांड प्याज काट देगा गुज्जर भोसड़ी   \n",
              "4                             बंगाली साड़ी पहना दीदी   \n",
              "5                            ऐ इंडिया आदमी जीता मरता   \n",
              "6  अक्कड़ बक्कड़ बंबे बो डीजल नब्बे पेट्रोल सौ सौ...   \n",
              "7  तीर कमान आदिवासी तीर कमान जय श्रीराम जय श्रीरा...   \n",
              "8        फैन असद ओवैसी साहब फैन मुजम्मिल थाली number   \n",
              "9                                 सब चूतिया रोटी राम   \n",
              "\n",
              "                                          final_text  \n",
              "0  नही सोच निकले सोच फंसा कैसेface_with_tears_of_...  \n",
              "1                            दिवाली देश पड़ाका फोडात  \n",
              "2              कुत्ता बिल्ली पाल लेना गलत फहमी नहीं।  \n",
              "3             तेरी गांड प्याज काट देगा गुज्जर भोसड़ी  \n",
              "4                             बंगाली साड़ी पहना दीदी  \n",
              "5                            ऐ इंडिया आदमी जीता मरता  \n",
              "6  अक्कड़ बक्कड़ बंबे बो डीजल नब्बे पेट्रोल सौ सौ...  \n",
              "7  तीर कमान आदिवासी तीर कमान जय श्रीराम जय श्रीरा...  \n",
              "8        फैन असद ओवैसी साहब फैन मुजम्मिल थाली number  \n",
              "9                                 सब चूतिया रोटी राम  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cef5f1d-746b-46d3-81ba-b719ca52579c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Clean Text</th>\n",
              "      <th>final_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>मैं ये नही सोच रहा की इसे निकले कैसे मैं ये सो...</td>\n",
              "      <td>नही सोच निकले सोच फंसा कैसेface_with_tears_of_...</td>\n",
              "      <td>नही सोच निकले सोच फंसा कैसेface_with_tears_of_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>और दिवाली में भी पूरा देश पड़ाका नहीं फोडात</td>\n",
              "      <td>दिवाली देश पड़ाका फोडात</td>\n",
              "      <td>दिवाली देश पड़ाका फोडात</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>कुत्ता बिल्ली पाल लेना मगर गलत फहमी कभी नहीं।</td>\n",
              "      <td>कुत्ता बिल्ली पाल लेना गलत फहमी नहीं।</td>\n",
              "      <td>कुत्ता बिल्ली पाल लेना गलत फहमी नहीं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>तेरी गांड में प्याज काट देगा गुज्जर भोसड़ी के</td>\n",
              "      <td>तेरी गांड प्याज काट देगा गुज्जर भोसड़ी</td>\n",
              "      <td>तेरी गांड प्याज काट देगा गुज्जर भोसड़ी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>बंगाली साड़ी ऐसे नहीं पहना जाता है दीदी</td>\n",
              "      <td>बंगाली साड़ी पहना दीदी</td>\n",
              "      <td>बंगाली साड़ी पहना दीदी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>ऐ इंडिया है यह आदमी दो बार जीता है  एक बार मरत...</td>\n",
              "      <td>ऐ इंडिया आदमी जीता मरता</td>\n",
              "      <td>ऐ इंडिया आदमी जीता मरता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>अक्कड़ बक्कड़ बंबे बो  डीजल नब्बे पेट्रोल सौ  ...</td>\n",
              "      <td>अक्कड़ बक्कड़ बंबे बो डीजल नब्बे पेट्रोल सौ सौ...</td>\n",
              "      <td>अक्कड़ बक्कड़ बंबे बो डीजल नब्बे पेट्रोल सौ सौ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>एक तीर एक कमान आदिवासी एक समान एक तीर एक कमान ...</td>\n",
              "      <td>तीर कमान आदिवासी तीर कमान जय श्रीराम जय श्रीरा...</td>\n",
              "      <td>तीर कमान आदिवासी तीर कमान जय श्रीराम जय श्रीरा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>आपका बहुत बड़ा फैन हूं असद ओवैसी साहब मैं आपका...</td>\n",
              "      <td>फैन असद ओवैसी साहब फैन मुजम्मिल थाली number</td>\n",
              "      <td>फैन असद ओवैसी साहब फैन मुजम्मिल थाली number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>तुम सब चूतिया हो रोटी राम</td>\n",
              "      <td>सब चूतिया रोटी राम</td>\n",
              "      <td>सब चूतिया रोटी राम</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cef5f1d-746b-46d3-81ba-b719ca52579c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7cef5f1d-746b-46d3-81ba-b719ca52579c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7cef5f1d-746b-46d3-81ba-b719ca52579c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model architecture\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, patience):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.patience = patience\n",
        "        self.counter=0\n",
        "        self.early_stop=False\n",
        "        self.min_delta = 5\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=0.3, num_layers = num_layers)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.sig = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x, h):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, h)\n",
        "        # print(lstm_out.shape)\n",
        "        lstm_out = lstm_out[:, -1, :] # getting the last time step output\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        # fully-connected layer\n",
        "        out = self.fc(lstm_out)\n",
        "        # out = self.fc2(out)\n",
        "        # sigmoid function\n",
        "        out = self.sig(out)\n",
        "        # return last sigmoid output\n",
        "        return out\n",
        "\n",
        "    def earlystop(self, validation_loss, train_loss):\n",
        "      if (validation_loss - train_loss) > self.min_delta:\n",
        "        self.counter +=1\n",
        "        if self.counter >= self.patience:  \n",
        "            self.early_stop = True\n",
        "    \n",
        "    def getearlystop(self):\n",
        "      return self.early_stop\n",
        "    \n",
        "    def getearlystopcnt(self):\n",
        "      return self.counter\n",
        "\n",
        "    def getpatience(self):\n",
        "      return self.patience\n",
        "    \n",
        "    def incearlystopcnt(self):\n",
        "      self.counter += 1\n",
        "    \n",
        "    def setearlystopcnt(self):\n",
        "      self.counter += 0"
      ],
      "metadata": {
        "id": "iYV0N6lJ2peX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 600\n",
        "num_layers = 2\n",
        "\n",
        "epochs = 10\n",
        "lr = 0.001 # learning rate"
      ],
      "metadata": {
        "id": "-OHn-SEd64cJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "def testLSTM(testdf):\n",
        "  # Load the saved LSTM model\n",
        "  model_path = '/content/drive/MyDrive/Colab Notebooks/models/lstm.pth'\n",
        "  model = torch.load(model_path)\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  total_f1 = 0\n",
        "  nb_eval_steps = 0\n",
        "  # encode to int\n",
        "  encoded_train_data = encode_word2int(testdf['final_text'])\n",
        "  labels = np.array(testdf['label'])\n",
        "  # maximum sequence length\n",
        "  MAX_SEQ_LEN = 100\n",
        "  # Padding the sentences\n",
        "  padded_X = []\n",
        "  for sentence in encoded_train_data:\n",
        "    if len(sentence) > MAX_SEQ_LEN:\n",
        "      padded_X.append(sentence[:MAX_SEQ_LEN])\n",
        "    else:\n",
        "      padded_X.append([0]*(MAX_SEQ_LEN-len(sentence)) + sentence)\n",
        "  padded_X = np.array(padded_X)\n",
        "  test_set = TensorDataset(torch.from_numpy(padded_X), torch.from_numpy(labels))\n",
        "  # create a data loader\n",
        "  test_loader = DataLoader(test_set, batch_size=32, pin_memory=True,num_workers=2, shuffle=False)\n",
        "  # perform evaluation loop on batches\n",
        "  val_loss = []\n",
        "  val_acc= []\n",
        "  running_loss_val = 0\n",
        "  correct_val = 0\n",
        "  total_val = 0\n",
        "  total_step_val = len(test_loader)\n",
        "  with torch.no_grad():\n",
        "    for texts, labels in tqdm(test_loader):\n",
        "      texts = texts.to(device) \n",
        "      labels = labels.to(device) \n",
        "      bs = labels.shape[0]  \n",
        "      zero_init = torch.zeros(num_layers,bs,hidden_dim).to(device)\n",
        "\n",
        "      h = tuple([zero_init, zero_init]) \n",
        "\n",
        "      preds = model(texts, h)\n",
        "      loss = nn.BCELoss()(preds.squeeze(), labels.float())\n",
        "      # val_loss.append(loss.item())\n",
        "      running_loss_val += loss.item()\n",
        "\n",
        "      # y_pred_val = torch.argmax(preds, dim=1)\n",
        "      preds = torch.round(preds.squeeze())\n",
        "      # y_val_list.extend(preds.tolist())\n",
        "      # print(preds.tolist())\n",
        "\n",
        "      correct_val += torch.sum(preds==labels).item()\n",
        "      total_val += labels.size(0)\n",
        "      output_preds_cpu=preds.cpu()\n",
        "      total_f1 += f1_score(labels.cpu(), preds.tolist(), average='macro')\n",
        "      nb_eval_steps += 1\n",
        "      # accuracy = torch.tensor(torch.sum(preds == labels).item() / len(preds)).item()        \n",
        "      # accs.append(accuracy)\n",
        "\n",
        "  val_loss.append(running_loss_val / total_step_val)\n",
        "  val_acc.append(100 * correct_val / total_val)\n",
        "  avg_f1 = total_f1 / nb_eval_steps\n",
        "  print(f'\\n\\nAccuracy : {np.mean(val_acc):.3f}%')\n",
        "  print(f'Macro f1-score : {avg_f1*100:.3f}%')\n",
        "\n",
        "testLSTM(test_df)"
      ],
      "metadata": {
        "id": "GwCmOJkm6cNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c519569a-e1d2-4606-be66-8cf3e138ca44"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 211/211 [00:04<00:00, 51.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy : 79.504%\n",
            "Macro f1-score : 78.984%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_intersection_points(train_df, val_df, new_testdf):\n",
        "  # Extract the column of interest from training and test dataframes\n",
        "  train_col = set(train_df[\"text\"])\n",
        "  test_col = set(new_testdf[\"text\"])\n",
        "\n",
        "  # Count the number of common rows between the two dataframes\n",
        "  common_rows = len(train_col.intersection(test_col))\n",
        "  print(\"Number of common rows between train and test:\", common_rows)\n",
        "\n",
        "  # Extract the column of interest from validation and test dataframes\n",
        "  valid_col = set(val_df[\"text\"])\n",
        "\n",
        "  # Count the number of common rows between the two dataframes\n",
        "  common_rows = len(valid_col.intersection(test_col))\n",
        "  print(\"Number of common rows between validation and test:\", common_rows)\n",
        "\n",
        "print_intersection_points(traindf, valdf, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0sXM9ZAfv5Y",
        "outputId": "60274c49-9484-4da6-bb0a-045783b37539"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common rows between train and test: 0\n",
            "Number of common rows between validation and test: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zCHw_JXFg8N8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}